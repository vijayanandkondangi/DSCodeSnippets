{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_FCNN_Book 3.ipynb","provenance":[],"authorship_tag":"ABX9TyMF8OFe7R5s58NXMGjOFHMC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9xlXZmPx5pBU"},"source":["**Deep Learning Notebook 3**\n","\n","Dataset: MNIST digits dataset available as part of Keras\n","\n","Objectives: Develop a FC NN model using tensorflow"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"twa-IZZ7JyFB","executionInfo":{"status":"ok","timestamp":1607779282613,"user_tz":-330,"elapsed":958,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}},"outputId":"3bfa7fca-7a08-4872-9e21-31c6f3e67be7"},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SJhAXHrk5jhq","executionInfo":{"status":"ok","timestamp":1607779289721,"user_tz":-330,"elapsed":8059,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Import the required libraries, modules\n","\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.python.framework import ops\n","from sklearn.model_selection import train_test_split\n","import math\n","from tensorflow.examples.tutorials.mnist import input_data\n","import matplotlib.pyplot as plt"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CR155MlUi89f","executionInfo":{"status":"ok","timestamp":1607779289724,"user_tz":-330,"elapsed":8058,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}},"outputId":"ad076095-6205-45ab-f25a-f14eb59dc2ea"},"source":["# Check the version details\n","\n","print(\"TF Version: \", tf.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TF Version:  1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MwOZOES3jTEe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607779290325,"user_tz":-330,"elapsed":8653,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}},"outputId":"ed274f5c-0e9a-4e87-a6fd-f729db0cc97f"},"source":["# Load a subset of records from the MNIST data set\n","\n","mnist = keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ab9q-ZAnj0I4","executionInfo":{"status":"ok","timestamp":1607779290327,"user_tz":-330,"elapsed":8651,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Normalize X by dividing by 255\n","\n","X_train = X_train.T / 255.0\n","X_test = X_test.T / 255.0"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"chV2e2zYXmdQ","executionInfo":{"status":"ok","timestamp":1607779290772,"user_tz":-330,"elapsed":9092,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Convert y to one-hot matrix\r\n","\r\n","y_train_temp = tf.one_hot(y_train, 6, axis = 0)\r\n","y_test_temp = tf.one_hot(y_test, 6, axis = 0)\r\n","\r\n","sess = tf.Session()\r\n","y_train = sess.run(y_train_temp)\r\n","y_test = sess.run(y_test_temp)\r\n","sess.close()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDUyajdOxhQl","executionInfo":{"status":"ok","timestamp":1607779291725,"user_tz":-330,"elapsed":10041,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Flatten X\r\n","\r\n","X_train = X_train.reshape(X_train.T.shape[0], -1).T\r\n","X_test = X_test.reshape(X_test.T.shape[0], -1).T"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7davT3SVXrt5","executionInfo":{"status":"ok","timestamp":1607779291731,"user_tz":-330,"elapsed":10043,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}},"outputId":"a3f5e855-ea27-4446-8155-690e02f40cd1"},"source":["# Verify shapes of X and y\r\n","\r\n","print (\"Number of training examples = \" + str(X_train.shape[1]))\r\n","print (\"Number of test examples = \" + str(X_test.shape[1]))\r\n","print (\"X_train shape: \" + str(X_train.shape))\r\n","print (\"y_train shape: \" + str(y_train.shape))\r\n","print (\"X_test shape: \" + str(X_test.shape))\r\n","print (\"y_test shape: \" + str(y_test.shape))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Number of training examples = 60000\n","Number of test examples = 10000\n","X_train shape: (784, 60000)\n","y_train shape: (6, 60000)\n","X_test shape: (784, 10000)\n","y_test shape: (6, 10000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0V06Qm1Wlz5p","executionInfo":{"status":"ok","timestamp":1607779291731,"user_tz":-330,"elapsed":10038,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Create placeholder tensors for the session\n","\n","def create_placeholders(n_x, n_y):\n","\n","  X = tf.placeholder(tf.float32, [n_x, None], name = \"X\")\n","  y = tf.placeholder(tf.float32, [n_y, None], name = \"y\")\n","\n","  return X, y"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"fYLhEg8FFqBl","executionInfo":{"status":"ok","timestamp":1607779291732,"user_tz":-330,"elapsed":10035,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Initialize weights of the NN\r\n","\r\n","def initialize_parameters():\r\n","\r\n","  # Input layer    : 784 input nodes\r\n","  # Hidden layer 1 : 200 neurons + Xavier initialization\r\n","  # Hidden layer 2 : 100 neurons + Xavier initialization\r\n","  # Output layer   : 6 output nodes\r\n","\r\n","  W1 = tf.get_variable(\"W1\", [200,784], initializer = tf.contrib.layers.xavier_initializer())\r\n","  b1 = tf.get_variable(\"b1\", [200,1], initializer = tf.zeros_initializer())\r\n","  W2 = tf.get_variable(\"W2\", [100,200], initializer = tf.contrib.layers.xavier_initializer())\r\n","  b2 = tf.get_variable(\"b2\", [100,1], initializer = tf.zeros_initializer())\r\n","  W3 = tf.get_variable(\"W3\", [6,100], initializer = tf.contrib.layers.xavier_initializer())\r\n","  b3 = tf.get_variable(\"b3\", [6,1], initializer = tf.zeros_initializer())\r\n","\r\n","  parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2, \"W3\": W3, \"b3\": b3}\r\n","\r\n","  return parameters"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"cSWAsGv8Kqbz","executionInfo":{"status":"ok","timestamp":1607779291733,"user_tz":-330,"elapsed":10032,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Forward propagation\r\n","\r\n","def forward_propagation(X, parameters):\r\n","\r\n","  W1 = parameters['W1']\r\n","  b1 = parameters['b1']\r\n","  W2 = parameters['W2']\r\n","  b2 = parameters['b2']\r\n","  W3 = parameters['W3']\r\n","  b3 = parameters['b3']\r\n","\r\n","  Z1 = tf.add(tf.matmul(W1, X), b1) \r\n","  A1 = tf.nn.relu(Z1)\r\n","  tf.nn.dropout(A1, 0.8)\r\n","  Z2 = tf.add(tf.matmul(W2, A1), b2) \r\n","  A2 = tf.nn.relu(Z2)\r\n","  tf.nn.dropout(A2, 0.8)\r\n","  Z3 = tf.add(tf.matmul(W3, A2), b3)\r\n","\r\n","  return Z3"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-MSHtZFLLDV","executionInfo":{"status":"ok","timestamp":1607779291734,"user_tz":-330,"elapsed":10028,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Define cost function\r\n","\r\n","def compute_cost(Z3, y):\r\n","\r\n","  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = tf.transpose(Z3), labels = tf.transpose(y)))\r\n","  return cost"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"JyUIgfisrJGw","executionInfo":{"status":"ok","timestamp":1607779291734,"user_tz":-330,"elapsed":10023,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Util for extracting mini batches\r\n","\r\n","def random_mini_batches(X, Y, mini_batch_size = 64):\r\n","    \"\"\"\r\n","    Creates a list of random minibatches from (X, Y)\r\n","    \r\n","    Arguments:\r\n","    X -- input data, of shape (input size, number of examples)\r\n","    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\r\n","    mini_batch_size - size of the mini-batches, integer\r\n","    \r\n","    Returns:\r\n","    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\r\n","    \"\"\"\r\n","    \r\n","    m = X.shape[1]                  # number of training examples\r\n","    mini_batches = []\r\n","    \r\n","    # Step 1: Shuffle (X, Y)\r\n","    permutation = list(np.random.permutation(m))\r\n","    shuffled_X = X[:, permutation]\r\n","    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\r\n","\r\n","    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\r\n","    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\r\n","    for k in range(0, num_complete_minibatches):\r\n","        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\r\n","        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\r\n","        mini_batch = (mini_batch_X, mini_batch_Y)\r\n","        mini_batches.append(mini_batch)\r\n","    \r\n","    # Handling the end case (last mini-batch < mini_batch_size)\r\n","    if m % mini_batch_size != 0:\r\n","        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\r\n","        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\r\n","        mini_batch = (mini_batch_X, mini_batch_Y)\r\n","        mini_batches.append(mini_batch)\r\n","    \r\n","    return mini_batches"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKFxcKFLMywZ","executionInfo":{"status":"ok","timestamp":1607779291735,"user_tz":-330,"elapsed":10020,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}}},"source":["# Implement model\r\n","\r\n","def model(X_train, y_train, X_test, y_test, learning_rate = 0.00001, num_epochs = 1500, minibatch_size = 2048, print_cost = True):\r\n","\r\n","  # Rerun model without overriding tf variables\r\n","  ops.reset_default_graph()\r\n","\r\n","  # Extract the shape of X & y\r\n","  (n_x, m) = X_train.shape\r\n","  n_y = y_train.shape[0]\r\n","\r\n","  # Create placeholders\r\n","  X, y = create_placeholders(n_x, n_y)\r\n","\r\n","  # Initialize parameters\r\n","  parameters = initialize_parameters()\r\n","\r\n","  # Initialize cost list\r\n","  costs = []\r\n","\r\n","  # Run forward propagation\r\n","  Z3 = forward_propagation(X, parameters)\r\n","\r\n","  # Calculate cost\r\n","  cost = compute_cost(Z3, y)\r\n","\r\n","  # Specify optimizer\r\n","  optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\r\n","\r\n","  # Initialize variables\r\n","  init = tf.global_variables_initializer()\r\n","\r\n","  # Initialize & invoke TF session\r\n","  with tf.Session() as sess:\r\n","    sess.run(init)\r\n","\r\n","    # For loop to iterate through the epochs\r\n","    for epoch in range(num_epochs):\r\n","      \r\n","      # Initialize epoch cost\r\n","      epoch_cost = 0.0\r\n","\r\n","      # Calculate No. of minibatches\r\n","      num_minibatches = int( m / minibatch_size ) \r\n","  \r\n","      # Evaluate minibatches\r\n","      minibatches = random_mini_batches(X_train, y_train, minibatch_size)\r\n","\r\n","      # For loop to iterate through every minibatch\r\n","      for minibatch in minibatches:\r\n","\r\n","        # Read the minibatch\r\n","        (minibatch_X, minibatch_Y) = minibatch\r\n","\r\n","        # Evaluate the minibatch cost\r\n","        _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, y: minibatch_Y})\r\n","\r\n","        # Accumulate average minibatch cost to epoch cost\r\n","        epoch_cost += minibatch_cost / minibatch_size\r\n","\r\n","      # For every epoch, print the total cost\r\n","      if print_cost == True and epoch % 100 == 0:\r\n","        print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\r\n","\r\n","      if print_cost == True and epoch % 5 == 0:\r\n","        costs.append(epoch_cost)\r\n","\r\n","    # Plot the learning curve as a function of No. of epochs\r\n","    plt.plot(np.squeeze(costs))\r\n","    plt.ylabel('cost')\r\n","    plt.xlabel('iterations (per fives)')\r\n","    plt.title(\"Learning rate =\" + str(learning_rate))\r\n","    plt.show()\r\n","\r\n","    # Save the final parameters\r\n","    parameters = sess.run(parameters)\r\n","    print (\"Parameters have been trained!\")\r\n","\r\n","    # Evaluate model\r\n","    correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(y))\r\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\r\n","\r\n","    # Print train and test accuracies\r\n","    print (\"Train Accuracy:\", accuracy.eval({X: X_train, y: y_train}))\r\n","    print (\"Test Accuracy:\", accuracy.eval({X: X_test, y: y_test}))\r\n","\r\n","  return parameters"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"id":"tbGHmVCbkBGG","executionInfo":{"status":"error","timestamp":1607779593698,"user_tz":-330,"elapsed":311982,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}},"outputId":"dfdecbfa-42e2-4c2c-b33c-7bba0e43dd92"},"source":["# Run the model for the train and test data sets\r\n","\r\n","parameters = model(X_train, y_train, X_test, y_test)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-12-130c0c3b3244>:14: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From <ipython-input-13-7b0d81c5435b>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Cost after epoch 0: 0.015954\n","Cost after epoch 100: 0.016176\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-99198dd06ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the model for the train and test data sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-793dcb87ea44>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, y_train, X_test, y_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Evaluate the minibatch cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Accumulate average minibatch cost to epoch cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7nnhtWJWsiXt","executionInfo":{"status":"ok","timestamp":1607779598245,"user_tz":-330,"elapsed":1012,"user":{"displayName":"Vijayanand Kondangi","photoUrl":"","userId":"11616880979817103659"}},"outputId":"e0c91618-6f84-40af-9850-fde95da546b9"},"source":["X_train.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(784, 60000)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"Npe-4DsbsmiM"},"source":[""]}]}